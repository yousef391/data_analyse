{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63386b82-5f39-4b68-beae-a3a82e6207ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering and Dimentionnality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7076d67-6bf1-462f-b35f-e4185716f06f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "1. Import the CIFAR-10 dataset using the following code and create a new dataset containing only the following classes: \"airplane,\" \"automobile,\" \"bird,\" and \"cat.\"\n",
    "\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487d9629-93ea-4f6b-bbb7-f3e8ef14a3ee",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">The CIFAR-10 dataset is composed of 60000 RGB images( 32x32 pixels), categorized into 10 classes with 6000 images per class. It is divided into 50000 training images and 10000 test images.\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "359a73e7-9b40-457c-b20f-62227ef1d7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X=(50000, 32, 32, 3), y=(50000, 1)\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "# load dataset\n",
    "(trainX, trainy), _ = cifar10.load_data()\n",
    "label_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "# summarize loaded dataset\n",
    "print('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc916f28-2f51-47f1-bd79-891b44c1d06c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "\n",
    "2. Visualize some samples from the dataset with their corresponding labels.\n",
    "\n",
    "3. Normalize the training data by dividing all values by 255.\n",
    "\n",
    "4. Visualize the data using a 2D plot by applying dimensionality reduction based on PCA with two components.\n",
    "\n",
    "5. Apply the K-means algorithm, K-means with PCA (with a variance of 95%), and K-means with LDA (3 components) on the normalized training data.\n",
    "\n",
    "6. Visualize the data after clustering using a 2D plot (use PCA with 2 components for dimensionality reduction) for each model. What do you observe?\n",
    "\n",
    "7. Compute the Davies-Bouldin score for all generated models.\n",
    "\n",
    "8. Display the confusion matrix and the classification reports for all models. What do you observe?\n",
    "\n",
    "9. Display some misclassifications for the best model (image with the true label and predicted label).\n",
    "\n",
    "10. Try to enhance the performance of the best model.\n",
    "<div/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
