{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f60bdda5-5048-44b9-9b93-50fab527bc76",
   "metadata": {},
   "source": [
    "# Classification algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435c2f39-2871-4f88-ae40-ab6e215b0f7d",
   "metadata": {},
   "source": [
    "### Dataset description, visualisation, and pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9136df6d-095d-430a-9439-670daedc144f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">The Heart Disease Detection dataset is composed of a set of characteristics used to determine if a patient has heart disease or not. Its main purpose is to perform classification based on the target variable, 'HeartDisease,' which indicates the presence of heart disease in the patient. This variable has integer values where 0 represents no disease and 1 indicates the presence of disease.\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839f2044-9e8b-4042-84a3-3cbffa517f6e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"> \n",
    "    \n",
    "1. Import the Heart Disease Detection dataset.\n",
    "2. Display and try to understand each feature in this dataset.\n",
    "3. Display a summary of the dataset.\n",
    "4. Verify if the dataset contains any missing values.\n",
    "5. Plot the distribution of samples according to the target variable HeartDisease. Determine if the dataset is balanced.\n",
    "6. Apply dummy encoding to all categorical features in the dataset.\n",
    "7. Display the Pearson correlation matrix. Is there a correlation with the class and between features by considering a thresholed of 0.5?\n",
    "8. Display the distribution of all features on all the scaled data (except binary features) using a histplot. What do you observe?\n",
    "9. Split the data into a training and a testing set using a ratio of 0.3.\n",
    "10. Normalize the data using z-score scaling.\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7656b6c6-d02a-434b-8e19-bcaac0b99e00",
   "metadata": {},
   "source": [
    "### Data training and performance evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e083643-a64d-4b38-9c42-961b39b8b4ba",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"> \n",
    "    \n",
    "1. Train the following algorithms on the generated training dataset: Gaussian Naive Bayes, KNN(K=3), and decision tree (max_depth=6).\n",
    "2. Display and save the tree generated by the decision tree algorithm.\n",
    "3. Implement the SVM algorithm from scratch and apply it to the dataset.\n",
    "4. Print the classification reports and confusion matrices of all models on the testing set. Discuss the obtained results.\n",
    "5. Display the ROC curves of the generated models in one plot.\n",
    "6. Which evaluation metric do you recommend for this dataset?\n",
    "7. Predict the class of the third sample from the testing set based on the best-performing model.\n",
    "8. Perform the cross-validation evaluation method on the best model based on the selected metric.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
